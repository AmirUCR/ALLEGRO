{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m>\u001b[0m Welcome to \u001b[38;5;208mALLEGRO\u001b[0m.\n",
      "\u001b[34m>\u001b[0m All unspecified command-line arguments default to the values in config.yaml.\n",
      "\u001b[34m>\u001b[0m mp_threshold is set to 0 and thus disabled. Saving all guides to memory.\n",
      "\u001b[34m>\u001b[0m Beta is set to 0 and thus disabled.\n",
      "\u001b[34m>\u001b[0m \u001b[38;5;208mALLEGRO\u001b[0m will minimize the set size.\n",
      "\u001b[34m>\u001b[0m filter_repetitive is set to True. Filtering guides with repetitive sequences.\n",
      "\u001b[34m>\u001b[0m Creating directory data/output/all_split_1_1\n",
      "\u001b[34m>\u001b[0m Reading species input file from data/input/train_all_split_1.csv\n",
      "\u001b[34m>\u001b[0m Selected scorer: dummy\n",
      "\u001b[34m>\u001b[0m Done with 869 species...\n",
      "\u001b[34m>\u001b[0m Created coversets for all species.\n",
      "\u001b[34m>\u001b[0m Setting up and solving the linear program...\n",
      "\u001b[34m> Status: MPSOLVER_OPTIMAL\u001b[0m\n",
      "\u001b[34m> \u001b[0mNumber of feasible candidate guides: 401\n",
      "\u001b[34m> \u001b[0mUsing randomized rounding with 1000 trials.\n",
      "> \u001b[0mTrial 1000\n",
      "\u001b[34m> \u001b[0mWinners are:\n",
      "\u001b[34m> \u001b[0mAAAGAAGCACTTTCTGGTTT\n",
      "\u001b[34m> \u001b[0mAAATCTGGAACATTATATTT\n",
      "\u001b[34m> \u001b[0mAAATCTTTGCGGAGGATGGC\n",
      "\u001b[34m> \u001b[0mAAATTTATATTACTAGGTCT\n",
      "\u001b[34m> \u001b[0mAAGAGTGTATCGATGAGATA\n",
      "\u001b[34m> \u001b[0mAAGGAGGTCGAGGCGTAGAT\n",
      "\u001b[34m> \u001b[0mAATCCGTTGTTGAAGGCACC\n",
      "\u001b[34m> \u001b[0mAATTGAGCAGTATCAGGGAA\n",
      "\u001b[34m> \u001b[0mACAAAGTGGATCGGAGGCCA\n",
      "\u001b[34m> \u001b[0mACAATTATGACTCTTTCACC\n",
      "\u001b[34m> \u001b[0mACCAAATGGATCGGTGGACA\n",
      "\u001b[34m> \u001b[0mACCAAATGGATTGGCGGACA\n",
      "\u001b[34m> \u001b[0mACCAAATGGATTGGTGGACA\n",
      "\u001b[34m> \u001b[0mACCAAGTGGATCGGCGGCCA\n",
      "\u001b[34m> \u001b[0mACCAAGTGGATCGGCGGGCA\n",
      "\u001b[34m> \u001b[0mACCAAGTGGATTGGCGGCCA\n",
      "\u001b[34m> \u001b[0mACCAAGTGGATTGGCGGTCA\n",
      "\u001b[34m> \u001b[0mACCAAGTGGATTGGTGGACA\n",
      "\u001b[34m> \u001b[0mACCAAGTGGATTGGTGGCCA\n",
      "\u001b[34m> \u001b[0mACCAAGTGGATTGGTGGTCA\n",
      "\u001b[34m> \u001b[0mACCCAATTGGTCATCAGTCC\n",
      "\u001b[34m> \u001b[0mACGAAATGGATTGGAGGTCA\n",
      "\u001b[34m> \u001b[0mACTAAATGGATTGGTGGTCA\n",
      "\u001b[34m> \u001b[0mACTAAGTGGATTGGTGGTCA\n",
      "\u001b[34m> \u001b[0mACTCATTTAACTCCAGCTAT\n",
      "\u001b[34m> \u001b[0mACTGAACCTAAATGGTTCAA\n",
      "\u001b[34m> \u001b[0mACTGAGCCAGAATGGTTCAA\n",
      "\u001b[34m> \u001b[0mACTGAGCCCAAGTGGTTCAA\n",
      "\u001b[34m> \u001b[0mACTGAGCCTGAGTGGTTCAA\n",
      "\u001b[34m> \u001b[0mACTGGTCTCTTCGTTGGATC\n",
      "\u001b[34m> \u001b[0mACTGGTGCTACTGGTTTCTT\n",
      "\u001b[34m> \u001b[0mACTTGCGGTCTTCGAAGATG\n",
      "\u001b[34m> \u001b[0mAGATAGTTCAAGTCTCCTCC\n",
      "\u001b[34m> \u001b[0mAGATGTTGCCGAACTCCTTG\n",
      "\u001b[34m> \u001b[0mAGCTCCTGTGCAAAGGCAGC\n",
      "\u001b[34m> \u001b[0mAGCTCGGCGCCGAAGAACAG\n",
      "\u001b[34m> \u001b[0mAGGAACCTACAACCAATTGA\n",
      "\u001b[34m> \u001b[0mAGGTAGATGCATTGGCGGTC\n",
      "\u001b[34m> \u001b[0mATACCAGTAATTCCAGCCCA\n",
      "\u001b[34m> \u001b[0mATATCAGCACCATGGTCAAT\n",
      "\u001b[34m> \u001b[0mATATCCTCATTCCAAACCTC\n",
      "\u001b[34m> \u001b[0mATCAGTATTGGAGGTGTCAT\n",
      "\u001b[34m> \u001b[0mATCAGTATTGGCGGTGTCAT\n",
      "\u001b[34m> \u001b[0mATCAGTATTGGTGGTGTCAT\n",
      "\u001b[34m> \u001b[0mATCCATTCTGCCAATCGACC\n",
      "\u001b[34m> \u001b[0mATCGGAACTGGTCTCTTCAT\n",
      "\u001b[34m> \u001b[0mATCGGAACTGGTCTCTTCGT\n",
      "\u001b[34m> \u001b[0mATCTTTCCATTCGGATTGAG\n",
      "\u001b[34m> \u001b[0mATGCCCTCCAATCCATTTAG\n",
      "\u001b[34m> \u001b[0mATGCTGCCCTTGAACCACTC\n",
      "\u001b[34m> \u001b[0mATGCTTCCCTTGAACCACTC\n",
      "\u001b[34m> \u001b[0mATGCTTCCTTTGAACCACTC\n",
      "\u001b[34m> \u001b[0mATGTATCGCTCTGGAGATCT\n",
      "\u001b[34m> \u001b[0mATGTGCAATACCAGACAGCA\n",
      "\u001b[34m> \u001b[0mATTATGTGCATGGGAATACT\n",
      "\u001b[34m> \u001b[0mATTGCCATGATCAGTATTGG\n",
      "\u001b[34m> \u001b[0mCACAACTTTGAGGTGGACAT\n",
      "\u001b[34m> \u001b[0mCACAGCGCAACAAAGTGGAT\n",
      "\u001b[34m> \u001b[0mCACAGCGCAACGAAATGGAT\n",
      "\u001b[34m> \u001b[0mCACAGCGCGACGAAATGGAT\n",
      "\u001b[34m> \u001b[0mCACAGTGCAACGAAATGGAT\n",
      "\u001b[34m> \u001b[0mCACAGTGCCACCAAATGGAT\n",
      "\u001b[34m> \u001b[0mCACATCCAGTTCATCGCCCT\n",
      "\u001b[34m> \u001b[0mCACATTGCCATGATCAGTAT\n",
      "\u001b[34m> \u001b[0mCACTTGCAAATGATTGCCAT\n",
      "\u001b[34m> \u001b[0mCACTTGCAGATGATCGCCAT\n",
      "\u001b[34m> \u001b[0mCAGAAGGACATCATGCCTGC\n",
      "\u001b[34m> \u001b[0mCATCTGCAAATGATTGCCAT\n",
      "\u001b[34m> \u001b[0mCATCTGCAGATGATAGCCAT\n",
      "\u001b[34m> \u001b[0mCATCTGCAGATGATCGCCAT\n",
      "\u001b[34m> \u001b[0mCATCTGCAGATGATCGCTAT\n",
      "\u001b[34m> \u001b[0mCATCTGCAGATGATTGCTAT\n",
      "\u001b[34m> \u001b[0mCATCTTCAGATGATCGCCAT\n",
      "\u001b[34m> \u001b[0mCATCTTCAGATGATTGCCAT\n",
      "\u001b[34m> \u001b[0mCATTTGCAAATGATCGCTAT\n",
      "\u001b[34m> \u001b[0mCATTTGCAAATGATTGCTAT\n",
      "\u001b[34m> \u001b[0mCATTTGCAGATGATTGCCAT\n",
      "\u001b[34m> \u001b[0mCATTTGCAGATGATTGCGAT\n",
      "\u001b[34m> \u001b[0mCCAAACGTCTCGGCCATCCA\n",
      "\u001b[34m> \u001b[0mCCACCATTACGTATTCATGA\n",
      "\u001b[34m> \u001b[0mCCCAGGTGAAGATGGAGGAG\n",
      "\u001b[34m> \u001b[0mCCCATACAGACACCAAAGAT\n",
      "\u001b[34m> \u001b[0mCCGTGGGCTGTGGATGTCAG\n",
      "\u001b[34m> \u001b[0mCGATCTCGCCGAGCTCGATG\n",
      "\u001b[34m> \u001b[0mCGCGGCTTCCGTATCGAGCT\n",
      "\u001b[34m> \u001b[0mCGGCACCTACAACCAGTTCA\n",
      "\u001b[34m> \u001b[0mCGTGGTTTCAGAATTGAACT\n",
      "\u001b[34m> \u001b[0mCGTGGTTTCCGTATTGAGCT\n",
      "\u001b[34m> \u001b[0mCTGCAAATGATTGCGATTGG\n",
      "\u001b[34m> \u001b[0mCTTCACTGGTCTGACTTCAA\n",
      "\u001b[34m> \u001b[0mGAAATTTATGTTCGTGCTCC\n",
      "\u001b[34m> \u001b[0mGAACCAGTAGATCCAACCCA\n",
      "\u001b[34m> \u001b[0mGACAACACATTTGGAATGGG\n",
      "\u001b[34m> \u001b[0mGACAACACGTTCGGAGCTGG\n",
      "\u001b[34m> \u001b[0mGACAACACTTTCGGTGCTGG\n",
      "\u001b[34m> \u001b[0mGACAGAAGCTGACCCATGGC\n",
      "\u001b[34m> \u001b[0mGACAGCGGCAAGTTCGACTG\n",
      "\u001b[34m> \u001b[0mGACCGCAAGTTCGCCGACAT\n",
      "\u001b[34m> \u001b[0mGACCGCAAGTTTGCCGACAT\n",
      "\u001b[34m> \u001b[0mGACCGCAAGTTTGCCGATAT\n",
      "\u001b[34m> \u001b[0mGACCGCAAGTTTGCTGATAT\n",
      "\u001b[34m> \u001b[0mGACGACCAAGTCAAGATCCG\n",
      "\u001b[34m> \u001b[0mGACGACCAAGTCAAGATTCG\n",
      "\u001b[34m> \u001b[0mGACGACCAGGTCAAGATCCG\n",
      "\u001b[34m> \u001b[0mGACGACCAGGTCAAGATTCG\n",
      "\u001b[34m> \u001b[0mGACGATCAAATCAAGATTCG\n",
      "\u001b[34m> \u001b[0mGACGATCAAGTCAAGATCCG\n",
      "\u001b[34m> \u001b[0mGACGATCAAGTCAAGATTCG\n",
      "\u001b[34m> \u001b[0mGACGATCAGGTCAAGATCCG\n",
      "\u001b[34m> \u001b[0mGACGATCAGGTCAAGATTCG\n",
      "\u001b[34m> \u001b[0mGAGACCGACAAGTTCGGTAC\n",
      "\u001b[34m> \u001b[0mGAGACGCTGCAATTGCACGC\n",
      "\u001b[34m> \u001b[0mGAGACGCTGCAATTGCATGC\n",
      "\u001b[34m> \u001b[0mGAGAGAAGCTGACCCATAGC\n",
      "\u001b[34m> \u001b[0mGAGAGCTTCTTCGACCTCGG\n",
      "\u001b[34m> \u001b[0mGAGCCTTCTCCTGGATATCA\n",
      "\u001b[34m> \u001b[0mGATAACTTCTTTGACATTGG\n",
      "\u001b[34m> \u001b[0mGATACTCTTCAACTTCATGC\n",
      "\u001b[34m> \u001b[0mGATATCATGCCAGCTGGAAA\n",
      "\u001b[34m> \u001b[0mGATCGATTCACAATGTTGTC\n",
      "\u001b[34m> \u001b[0mGATCGCAAGTTTGCGGATAT\n",
      "\u001b[34m> \u001b[0mGATCGCAAGTTTGCTGATAT\n",
      "\u001b[34m> \u001b[0mGATGACCAAGTCAAGATCCG\n",
      "\u001b[34m> \u001b[0mGATGACCAAGTCAAGATTCG\n",
      "\u001b[34m> \u001b[0mGATGACCAAGTTAAGATCCG\n",
      "\u001b[34m> \u001b[0mGATGACCAGGTCAAGATCAG\n",
      "\u001b[34m> \u001b[0mGATGACCAGGTCAAGATCCG\n",
      "\u001b[34m> \u001b[0mGATGACCAGGTCAAGATTCG\n",
      "\u001b[34m> \u001b[0mGATGACCAGGTGAAGATTCG\n",
      "\u001b[34m> \u001b[0mGATGATCAAGTAAAGATCCG\n",
      "\u001b[34m> \u001b[0mGATGATCAAGTCAAGATCCG\n",
      "\u001b[34m> \u001b[0mGATGATCAAGTCAAGATTCG\n",
      "\u001b[34m> \u001b[0mGATGATCAAGTGAAGATTCG\n",
      "\u001b[34m> \u001b[0mGATGATCAGATCAAGATTCG\n",
      "\u001b[34m> \u001b[0mGATGATCAGGTCAAGATCCG\n",
      "\u001b[34m> \u001b[0mGATGATCAGGTCAAGATTCG\n",
      "\u001b[34m> \u001b[0mGATGATGTCGTCGATGTGCT\n",
      "\u001b[34m> \u001b[0mGATGGAATGTCTTGGTGAAA\n",
      "\u001b[34m> \u001b[0mGATGGCTGAAAGTGAAGTTA\n",
      "\u001b[34m> \u001b[0mGCGAGCAACCTCGCCAACGT\n",
      "\u001b[34m> \u001b[0mGCGCCAGAAGACCTGCTTGA\n",
      "\u001b[34m> \u001b[0mGCGCCGGTACACATGTCGCA\n",
      "\u001b[34m> \u001b[0mGCGCCGGTGCACATATCGCA\n",
      "\u001b[34m> \u001b[0mGCTACATTGGCTTCAAGTAC\n",
      "\u001b[34m> \u001b[0mGCTGGAATTACTGGTACAAC\n",
      "\u001b[34m> \u001b[0mGGATGCGATGTTATCATCGT\n",
      "\u001b[34m> \u001b[0mGGCCACGGCACCACCATTGG\n",
      "\u001b[34m> \u001b[0mGGCCATCCATGGGAAATAGT\n",
      "\u001b[34m> \u001b[0mGGCGAAATCTACGTCCGTTC\n",
      "\u001b[34m> \u001b[0mGGCGAGAACAAGACCTTCGT\n",
      "\u001b[34m> \u001b[0mGGCGGCCACGGCACCACCAT\n",
      "\u001b[34m> \u001b[0mGGCTTGTCGACCTTGCCGTT\n",
      "\u001b[34m> \u001b[0mGGCTTGTCGATCTTACCATT\n",
      "\u001b[34m> \u001b[0mGGCTTGTCGATCTTGCCATT\n",
      "\u001b[34m> \u001b[0mGGCTTGTCGATCTTGCCGTT\n",
      "\u001b[34m> \u001b[0mGGCTTGTCGATCTTTCCGTT\n",
      "\u001b[34m> \u001b[0mGGTATTCCGAAAGGTGTTAA\n",
      "\u001b[34m> \u001b[0mGGTTGTAGGTGCCGCCGTAG\n",
      "\u001b[34m> \u001b[0mGGTTTGTCAATCTTGCCATT\n",
      "\u001b[34m> \u001b[0mGTAAACATATCCCTTTGAAT\n",
      "\u001b[34m> \u001b[0mGTAAACATATCTCTCTGGAT\n",
      "\u001b[34m> \u001b[0mGTAAACATATCTCTTTGAAT\n",
      "\u001b[34m> \u001b[0mGTAAACATATCTCTTTGGAT\n",
      "\u001b[34m> \u001b[0mGTAAAGATATCACGTTGGAT\n",
      "\u001b[34m> \u001b[0mGTAAAGATATCTCTCTGAAT\n",
      "\u001b[34m> \u001b[0mGTAAAGATATCTCTTTGAAT\n",
      "\u001b[34m> \u001b[0mGTATAGAAACCACCAGAAAC\n",
      "\u001b[34m> \u001b[0mGTCATGGGTATCTTGAAGGC\n",
      "\u001b[34m> \u001b[0mGTCCGTATCATCAACATGTA\n",
      "\u001b[34m> \u001b[0mGTCGACAATACCTTCGGTGC\n",
      "\u001b[34m> \u001b[0mGTCGATAACACCTTTGGCAT\n",
      "\u001b[34m> \u001b[0mGTGAACATATCTCTTTGAAT\n",
      "\u001b[34m> \u001b[0mGTGAACATATCTCTTTGGAT\n",
      "\u001b[34m> \u001b[0mGTGAAGATATCTCGCTGAAT\n",
      "\u001b[34m> \u001b[0mGTGAAGATGTCTCGCTGGAT\n",
      "\u001b[34m> \u001b[0mGTGCGGAACCAGAACTTGTA\n",
      "\u001b[34m> \u001b[0mTATGCTGGAGAAATCATGCA\n",
      "\u001b[34m> \u001b[0mTCCGCCACCAAGTGGATTGG\n",
      "\u001b[34m> \u001b[0mTCCGGTGCCTTCGTGCTCGT\n",
      "\u001b[34m> \u001b[0mTCGATCATACCTTGACCAGC\n",
      "\u001b[34m> \u001b[0mTCGTGCACAGTGCGACCAAG\n",
      "\u001b[34m> \u001b[0mTCTGCTACCAAGTGGATTGG\n",
      "\u001b[34m> \u001b[0mTCTTCCCGTGGATGGGAGAG\n",
      "\u001b[34m> \u001b[0mTGACGAGCAGGAGGATAAGC\n",
      "\u001b[34m> \u001b[0mTGCGCACTCAGCGGCATCAC\n",
      "\u001b[34m> \u001b[0mTGTCCCAGAACTTGAGGCCG\n",
      "\u001b[34m> \u001b[0mTTACAAATGATTGCTATTGG\n",
      "\u001b[34m> \u001b[0mTTCATTTGGCGAATGGTCAA\n",
      "\u001b[34m> \u001b[0mTTCTCAAAGACATCGACAGT\n",
      "\u001b[34m> \u001b[0mTTCTCGAAGACATCGACAGT\n",
      "\u001b[34m> \u001b[0mTTGATCTCAGCCATGAGAGC\n",
      "\u001b[34m> \u001b[0mTTGCAAATGATTGCAATTGG\n",
      "\u001b[34m> \u001b[0mTTGCAGATGATTGCAATTGG\n",
      "\u001b[34m> \u001b[0mTTGCAGATGATTGCCATCGG\n",
      "\u001b[34m> \u001b[0mTTGGTAGACATTCCAGGTGA\n",
      "\u001b[34m> \u001b[0mTTGTACACCTTCTTCCACCG\n",
      "\u001b[34m>\u001b[0m Writing to file: data/output/all_split_1_1/all_split_1.txt\n",
      "\u001b[34m>\u001b[0m Done. Check data/output/all_split_1_1/all_split_1.csv for the output.\n",
      "\u001b[34m>\u001b[0m Clustering guides: Guides in the same cluster have an identical sequence for the first 10 nucleotides after the PAM (3' to 5').\n",
      "\u001b[34m>\u001b[0m Guides in the same cluster may mismatch up to 4 nucleotides after the seed region.\n",
      "\u001b[34m>\u001b[0m Done clustering. Added a new column 'cluster' to data/output/all_split_1_1/all_split_1.csv\n",
      "\u001b[34m>\u001b[0m The output guide RNA set contains 155 clusters.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Bio import SeqIO\n",
    "from sklearn.model_selection import KFold\n",
    "from src.utils.guide_finder import GuideFinder\n",
    "\n",
    "\n",
    "def find_first_match(list1, list2):\n",
    "    for index, item in enumerate(list2):\n",
    "        if item in list1:\n",
    "            return index\n",
    "    return -1  # If no match found.\n",
    "\n",
    "\n",
    "def hamming_distance(str1: str, str2: str, length: int) -> int:\n",
    "    \"\"\"\n",
    "    Calculates the Hamming distance between two strings up to a specified length.\n",
    "    \"\"\"\n",
    "    if len(str1) < length or len(str2) < length:\n",
    "        raise ValueError('Strings must have a length of at least {n}'.format(n=length))\n",
    "\n",
    "    return sum(ch1 != ch2 for ch1, ch2 in zip(str1[:length], str2[:length]))\n",
    "\n",
    "\n",
    "def get_record_metadata(record):\n",
    "    # This gene's own name -- Usually N/A for unannotated CDS files or chromosomes/scaffolds\n",
    "    gene_match = re.search(gene_regex, record.description)\n",
    "    gene_name = gene_match.group(1) if gene_match is not None else 'N/A'\n",
    "\n",
    "    # This gene's own protein id e.g., XP_022674739.1\n",
    "    protein_id_match = re.search(protein_id_regex, record.description)\n",
    "    protein_id = protein_id_match.group(1) if protein_id_match is not None else 'N/A'\n",
    "\n",
    "    # For example, [orthologous_to_ref_protein=XP_022674739.1], extracts XP_022674739.1\n",
    "    ortho_prot_to_match = re.search(orthologous_protein_regex, record.description)\n",
    "    ortho_prot_id = ortho_prot_to_match.group(1) if ortho_prot_to_match is not None else 'N/A'\n",
    "\n",
    "    # For example, [orthologous_to_gene=HIS7], extracts HIS7\n",
    "    ortho_gene_to_match = re.search(orthologous_name_regex, record.description)\n",
    "    ortho_gene_name = ortho_gene_to_match.group(1) if ortho_gene_to_match is not None else 'N/A'\n",
    "\n",
    "    return gene_name, protein_id, ortho_prot_id, ortho_gene_name\n",
    "\n",
    "\n",
    "gene_regex = r'\\[gene=(.*?)\\]'\n",
    "tag_regex = r'\\[locus_tag=(.*?)\\]'\n",
    "protein_id_regex = r'\\[protein_id=(.*?)\\]'\n",
    "reference_species_regex = r'\\[ref_species=(.*?)\\]'\n",
    "orthologous_name_regex = r'\\[orthologous_to_gene=(.*?)\\]'\n",
    "orthologous_protein_regex = r'\\[orthologous_to_ref_protein=(.*?)\\]'\n",
    "\n",
    "config = '''\n",
    "# ---\n",
    "experiment_name: {experiment_name}\n",
    "# ---\n",
    "\n",
    "# ---\n",
    "input_directory: 'data/input/cds/orthogroups/'\n",
    "input_species_path: {input_species_path}\n",
    "input_species_path_column: 'cds_file_name'\n",
    "# ---\n",
    "\n",
    "# ---\n",
    "track: {track}\n",
    "# ---\n",
    "\n",
    "# ---\n",
    "multiplicity: {mult}\n",
    "# ---\n",
    "\n",
    "# ---\n",
    "beta: {beta}\n",
    "# ---\n",
    "\n",
    "# ---\n",
    "scorer: {scorer}\n",
    "# ---\n",
    "\n",
    "# ---\n",
    "filter_repetitive: True\n",
    "# ---\n",
    "\n",
    "# ---\n",
    "mp_threshold: {mp_threshold}\n",
    "# ---\n",
    "\n",
    "# ---\n",
    "num_trials: 1000\n",
    "# ---\n",
    "\n",
    "# ---\n",
    "cluster_guides: True\n",
    "seed_region_is_n_from_pam: 10\n",
    "mismatches_allowed_after_seed_region: 4\n",
    "# ---\n",
    "'''\n",
    "\n",
    "df = pd.read_csv('data/input/final_ncbi_concat_1k_input_species.csv')\n",
    "\n",
    "# Set the random seed for reproducibility.\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Shuffle the data.\n",
    "df = df.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "\n",
    "# Initialize the KFold cross-validator.\n",
    "kfold = KFold(n_splits=10)\n",
    "\n",
    "split = 1\n",
    "for train_index, test_index in kfold.split(df):\n",
    "    train, test = df.iloc[train_index], df.iloc[test_index]\n",
    "\n",
    "    new_exp_name = 'all_split_' + str(split)\n",
    "    train_new_path = 'data/input/train_' + new_exp_name + '.csv'\n",
    "    train.to_csv(train_new_path, index=False)\n",
    "\n",
    "    test_new_path = 'data/input/test_' + new_exp_name + '.csv'\n",
    "    test.to_csv(test_new_path, index=False)\n",
    "\n",
    "    context = {\n",
    "        'experiment_name': new_exp_name,\n",
    "        'input_species_path': train_new_path,\n",
    "        'track': 'track_a',\n",
    "        'scorer': 'dummy',\n",
    "        'beta': 0,\n",
    "        'mult': '1',\n",
    "        'include_repetitive': True,\n",
    "        'mp_threshold': 0\n",
    "    }\n",
    "\n",
    "    config_name = 'temp_config_' + str(split) + '.yaml'\n",
    "    with open(config_name, 'w') as f:\n",
    "        f.write(config.format(**context))\n",
    "\n",
    "    # Call ALLEGRO\n",
    "    os.system('python src/main.py --config ' + config_name)\n",
    "\n",
    "    split_out = pd.read_csv(r'data/output/all_split_{split}/all_split_{split}.csv')\n",
    "\n",
    "    library = split_out.sequence.unique()\n",
    "\n",
    "    test_df = pd.read_csv(r'data/input/test_all_split_{split}.csv')\n",
    "    test_df = test_df.drop(columns=['genome_file_name'])\n",
    "\n",
    "    df_covered_list = list()\n",
    "    df_strands = list()\n",
    "    df_mismatch = list()\n",
    "    df_locations = list()\n",
    "    df_gene_names = list()\n",
    "    df_protein_ids = list()\n",
    "    df_ortho_prot_ids = list()\n",
    "    df_ortho_gene_names = list()\n",
    "    df_lib_partial_match = list()\n",
    "\n",
    "    gf = GuideFinder()\n",
    "    cds_base_path = 'data/input/cds/orthogroups/'\n",
    "\n",
    "    for label, row in test_df.iterrows():\n",
    "        species_is_covered = False\n",
    "        records_path = cds_base_path + row.cds_file_name\n",
    "        records = list(SeqIO.parse(open(records_path), 'fasta'))\n",
    "\n",
    "        for record in records:\n",
    "            (guides_list,\n",
    "            _guides_context_list,\n",
    "            strands_list,\n",
    "            locations_list) = gf.identify_guides_and_indicate_strand(\n",
    "                pam='NGG',\n",
    "                sequence=str(record.seq).upper(),\n",
    "                protospacer_length=20,\n",
    "                context_toward_five_prime=0,\n",
    "                context_toward_three_prime=0,\n",
    "                filter_repetitive=False\n",
    "            )\n",
    "\n",
    "            # Attempt to find an exact match.\n",
    "            match = find_first_match(library, guides_list)\n",
    "            if match != -1:\n",
    "                gene_name, protein_id, ortho_prot_id, ortho_gene_name = get_record_metadata(record)\n",
    "\n",
    "                df_covered_list.append(guides_list[match])\n",
    "                df_locations.append(locations_list[match])\n",
    "                df_strands.append(strands_list[match])\n",
    "                df_gene_names.append(gene_name)\n",
    "                df_protein_ids.append(protein_id)\n",
    "                df_ortho_prot_ids.append(ortho_prot_id)\n",
    "                df_ortho_gene_names.append(ortho_gene_name)\n",
    "                df_lib_partial_match.append('N/A')\n",
    "                df_mismatch.append('N/A')\n",
    "\n",
    "                species_is_covered = True\n",
    "                break  # This species has been covered.\n",
    "        \n",
    "        if species_is_covered == False:\n",
    "            partial_matches = list()\n",
    "\n",
    "            # Attempt to find partial matches.\n",
    "            mm_allowed = 4\n",
    "            req_match_len = 10\n",
    "            \n",
    "            best_record = None\n",
    "            smallest_mm = mm_allowed + 1\n",
    "            best_lib_guide = ''\n",
    "            best_test_guide = ''\n",
    "            best_test_guide_loc = 0\n",
    "            best_test_guide_strand = ''\n",
    "\n",
    "            for record in records:\n",
    "                (guides_list,\n",
    "                _guides_context_list,\n",
    "                strands_list,\n",
    "                locations_list) = gf.identify_guides_and_indicate_strand(\n",
    "                    pam='NGG',\n",
    "                    sequence=str(record.seq).upper(),\n",
    "                    protospacer_length=20,\n",
    "                    context_toward_five_prime=0,\n",
    "                    context_toward_three_prime=0,\n",
    "                    filter_repetitive=False\n",
    "                )\n",
    "\n",
    "                for idx, test_guide in enumerate(guides_list):\n",
    "                    for lib_guide in library:\n",
    "                        \n",
    "                        distance_after_seed = hamming_distance(lib_guide, test_guide, req_match_len)\n",
    "                        \n",
    "                        if lib_guide[req_match_len:] == test_guide[req_match_len:] and distance_after_seed < mm_allowed and distance_after_seed < smallest_mm:\n",
    "                            \n",
    "                            best_record = record\n",
    "                            best_lib_guide = lib_guide\n",
    "                            best_test_guide = test_guide\n",
    "                            smallest_mm = distance_after_seed\n",
    "                            best_test_guide_loc = locations_list[idx]\n",
    "                            best_test_guide_strand = strands_list[idx]\n",
    "\n",
    "                            species_is_covered = True\n",
    "\n",
    "            if species_is_covered:\n",
    "                gene_name, protein_id, ortho_prot_id, ortho_gene_name = get_record_metadata(best_record)\n",
    "\n",
    "                df_covered_list.append(best_test_guide)\n",
    "                df_locations.append(best_test_guide_loc)\n",
    "                df_strands.append(best_test_guide_strand)\n",
    "                df_gene_names.append(gene_name)\n",
    "                df_protein_ids.append(protein_id)\n",
    "                df_ortho_prot_ids.append(ortho_prot_id)\n",
    "                df_ortho_gene_names.append(ortho_gene_name)\n",
    "                df_mismatch.append(smallest_mm)\n",
    "                df_lib_partial_match.append(best_lib_guide)\n",
    "                \n",
    "\n",
    "            # No match.\n",
    "            elif species_is_covered == False:\n",
    "                df_covered_list.append('Not covered')\n",
    "                df_strands.append('Not covered')\n",
    "                df_locations.append('Not covered')\n",
    "                df_gene_names.append('Not covered')\n",
    "                df_protein_ids.append('Not covered')\n",
    "                df_ortho_prot_ids.append('Not covered')\n",
    "                df_ortho_gene_names.append('Not covered')\n",
    "                df_mismatch.append('Not covered')\n",
    "                df_lib_partial_match.append('Not covered')\n",
    "            \n",
    "        test_df['covered_by'] = df_covered_list\n",
    "        test_df['partial_match'] = df_lib_partial_match\n",
    "        test_df['mismatch'] = df_mismatch\n",
    "        test_df['strand'] = df_strands\n",
    "        test_df['location'] = df_locations\n",
    "        test_df['gene_name'] = df_gene_names\n",
    "        test_df['protein_id'] = df_protein_ids\n",
    "        test_df['ortho_prot_id'] = df_ortho_prot_ids\n",
    "        test_df['ortho_gene_name'] = df_ortho_gene_names\n",
    "\n",
    "        test_df.to_csv(r'test_{split}_results.csv', index=False)\n",
    "\n",
    "    split += 1\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "allegro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "66305d5341bcc90f0e236382a922a6a93724369df31dd2302786be3a10a6587f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
