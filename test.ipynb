{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import multiprocessing\n",
    "\n",
    "\n",
    "def count_records_in_file(filename):\n",
    "    return len([1 for line in open(filename) if line.startswith('>')])\n",
    "\n",
    "\n",
    "def process_file(filename):\n",
    "    return filename, count_records_in_file(filename)\n",
    "\n",
    "\n",
    "def process_files(files):\n",
    "    return [process_file(file) for file in files]\n",
    "\n",
    "\n",
    "# directory: Path to the directory containing the FASTA files\n",
    "def get_max(directory: str) -> int:\n",
    "    # Get the list of files in the directory\n",
    "    files = [os.path.join(directory, file) for file in os.listdir(directory) if file.endswith('.fna')]\n",
    "\n",
    "    # Set the number of processes\n",
    "    num_processes = multiprocessing.cpu_count()\n",
    "\n",
    "    # Split the files into chunks for each process\n",
    "    chunks = [files[i:i + num_processes] for i in range(0, len(files), num_processes)]\n",
    "\n",
    "    # Create a pool of processes\n",
    "    pool = multiprocessing.Pool(processes=num_processes)\n",
    "\n",
    "    # Map the process_files function to each chunk and get the results\n",
    "    results = pool.map(process_files, chunks)\n",
    "\n",
    "    # Flatten the results list\n",
    "    results = [item for sublist in results for item in sublist]\n",
    "\n",
    "    # Find the file with the maximum record count\n",
    "    max_file, max_count = max(results, key=lambda x: x[1])\n",
    "\n",
    "    # print(f'The file with the most records is {max_file} with {max_count} records.')\n",
    "\n",
    "    return max_count\n",
    "\n",
    "\n",
    "# directory: Path to the directory containing the FASTA files\n",
    "def count_records(directory: str) -> int:\n",
    "    # Get the list of files in the directory\n",
    "    files = [os.path.join(directory, file) for file in os.listdir(directory) if file.endswith('.fna')]\n",
    "\n",
    "    # Set the number of processes\n",
    "    num_processes = multiprocessing.cpu_count()\n",
    "\n",
    "    # Split the files into chunks for each process\n",
    "    chunks = [files[i:i + num_processes] for i in range(0, len(files), num_processes)]\n",
    "\n",
    "    # Create a pool of processes\n",
    "    pool = multiprocessing.Pool(processes=num_processes)\n",
    "\n",
    "    # Map the process_files function to each chunk and get the results\n",
    "    results = pool.map(process_files, chunks)\n",
    "\n",
    "    # Flatten the results list\n",
    "    results = [item for sublist in results for item in sublist]\n",
    "\n",
    "    # Find the sum of the records count\n",
    "    return sum(t[1] for t in results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "411106"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_records('data/input/genomes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32723250"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_max('data/input/genomes') * 966"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
